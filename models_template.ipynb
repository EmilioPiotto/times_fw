{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from backend.data_processing_service import DataProcessingService\n",
    "from backend.model_service import ModelService, LinRegNN\n",
    "\n",
    "# Initialize DataProcessingService\n",
    "data_processor = DataProcessingService(seq_length=10, pred_window=1, batch_size=10)\n",
    "data = np.loadtxt('data/normalized_apple_prices.csv')\n",
    "# data = data_processor.get_sample_data(length=50)\n",
    "\n",
    "# Normalize the data\n",
    "data_normalized, scaler = data_processor.normalize_data(data)\n",
    "\n",
    "# Create sequences\n",
    "x_data, y_data = data_processor.create_sequences(data_normalized)\n",
    "\n",
    "# Split data into training and test sets\n",
    "x_train, x_test, y_train, y_test = data_processor.split_data(x_data, y_data, train_ratio=0.8)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([102, 10, 1]) torch.Size([102, 1, 1]) torch.Size([26, 10, 1]) torch.Size([26, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/13], Loss: 0.2736                           \n",
      "Epoch [2/13], Loss: 0.2413                           \n",
      "Epoch [3/13], Loss: 0.4813                           \n",
      "Epoch [4/13], Loss: 0.5030                           \n",
      "Epoch [5/13], Loss: 1.2694                           \n",
      "Checkpoint saved at backend/checkpoints/test_5.pth   \n",
      "Epoch [6/13], Loss: 1.3971                           \n",
      "Epoch [7/13], Loss: 2.0040                           \n",
      "Epoch [8/13], Loss: 1.4015                           \n",
      "Epoch [9/13], Loss: 1.4608                           \n",
      "Epoch [10/13], Loss: 0.8221                          \n",
      "Checkpoint saved at backend/checkpoints/test_10.pth  \n",
      "Epoch [11/13], Loss: 0.8945                          \n",
      "Epoch [12/13], Loss: 0.4971                          \n",
      "Epoch [13/13], Loss: 0.6684                          \n",
      "Test Loss: 0.1256                                    \n",
      "Epoch [1/18], Loss: 0.4427                                                      \n",
      "Epoch [2/18], Loss: 0.2173                                                      \n",
      "Epoch [3/18], Loss: 1.6537                                                      \n",
      "Epoch [4/18], Loss: 7.2430                                                      \n",
      "Epoch [5/18], Loss: 1.6585                                                      \n",
      "Checkpoint saved at backend/checkpoints/test_5.pth                              \n",
      "Epoch [6/18], Loss: 2.1314                                                      \n",
      "Epoch [7/18], Loss: 4.4179                                                      \n",
      "Epoch [8/18], Loss: 7.0709                                                      \n",
      "Epoch [9/18], Loss: 11.2692                                                     \n",
      "Epoch [10/18], Loss: 11.3800                                                    \n",
      "Checkpoint saved at backend/checkpoints/test_10.pth                             \n",
      "Epoch [11/18], Loss: 11.0108                                                    \n",
      "Epoch [12/18], Loss: 7.8555                                                     \n",
      "Epoch [13/18], Loss: 6.4753                                                     \n",
      "Epoch [14/18], Loss: 4.2155                                                     \n",
      "Epoch [15/18], Loss: 3.8293                                                     \n",
      "Checkpoint saved at backend/checkpoints/test_15.pth                             \n",
      "Epoch [16/18], Loss: 2.7148                                                     \n",
      "Epoch [17/18], Loss: 2.9972                                                     \n",
      "Epoch [18/18], Loss: 2.4623                                                     \n",
      "Test Loss: 0.3972                                                               \n",
      "Epoch [1/20], Loss: 0.1444                                                      \n",
      "Epoch [2/20], Loss: 0.0643                                                      \n",
      "Epoch [3/20], Loss: 0.1501                                                      \n",
      "Epoch [4/20], Loss: 0.0637                                                      \n",
      "Epoch [5/20], Loss: 0.1843                                                      \n",
      "Checkpoint saved at backend/checkpoints/test_5.pth                              \n",
      "Epoch [6/20], Loss: 0.0808                                                      \n",
      "Epoch [7/20], Loss: 0.2098                                                      \n",
      "Epoch [8/20], Loss: 0.0890                                                      \n",
      "Epoch [9/20], Loss: 0.2084                                                      \n",
      "Epoch [10/20], Loss: 0.0834                                                     \n",
      "Checkpoint saved at backend/checkpoints/test_10.pth                             \n",
      "Epoch [11/20], Loss: 0.1898                                                     \n",
      "Epoch [12/20], Loss: 0.0733                                                     \n",
      "Epoch [13/20], Loss: 0.1719                                                     \n",
      "Epoch [14/20], Loss: 0.0663                                                     \n",
      "Epoch [15/20], Loss: 0.1622                                                     \n",
      "Checkpoint saved at backend/checkpoints/test_15.pth                             \n",
      "Epoch [16/20], Loss: 0.0641                                                     \n",
      "Epoch [17/20], Loss: 0.1611                                                     \n",
      "Epoch [18/20], Loss: 0.0660                                                     \n",
      "Epoch [19/20], Loss: 0.1663                                                     \n",
      "Epoch [20/20], Loss: 0.0705                                                     \n",
      "Checkpoint saved at backend/checkpoints/test_20.pth                             \n",
      "Test Loss: 0.0199                                                               \n",
      "Epoch [1/18], Loss: 0.3045                                                       \n",
      "Epoch [2/18], Loss: 0.0467                                                       \n",
      "Epoch [3/18], Loss: 0.1560                                                       \n",
      "Epoch [4/18], Loss: 0.1125                                                       \n",
      "Epoch [5/18], Loss: 0.3189                                                       \n",
      "Checkpoint saved at backend/checkpoints/test_5.pth                               \n",
      "Epoch [6/18], Loss: 0.2724                                                       \n",
      "Epoch [7/18], Loss: 0.5367                                                       \n",
      "Epoch [8/18], Loss: 0.3461                                                       \n",
      "Epoch [9/18], Loss: 0.5136                                                       \n",
      "Epoch [10/18], Loss: 0.2579                                                      \n",
      "Checkpoint saved at backend/checkpoints/test_10.pth                              \n",
      "Epoch [11/18], Loss: 0.3745                                                      \n",
      "Epoch [12/18], Loss: 0.1681                                                      \n",
      "Epoch [13/18], Loss: 0.2846                                                      \n",
      "Epoch [14/18], Loss: 0.1284                                                      \n",
      "Epoch [15/18], Loss: 0.2553                                                      \n",
      "Checkpoint saved at backend/checkpoints/test_15.pth                              \n",
      "Epoch [16/18], Loss: 0.1246                                                      \n",
      "Epoch [17/18], Loss: 0.2679                                                      \n",
      "Epoch [18/18], Loss: 0.1456                                                      \n",
      "Test Loss: 0.0277                                                                \n",
      "Epoch [1/17], Loss: 0.1691                                                       \n",
      "Epoch [2/17], Loss: 0.0366                                                       \n",
      "Epoch [3/17], Loss: 0.0409                                                       \n",
      "Epoch [4/17], Loss: 0.0293                                                       \n",
      "Epoch [5/17], Loss: 0.0334                                                       \n",
      "Checkpoint saved at backend/checkpoints/test_5.pth                               \n",
      "Epoch [6/17], Loss: 0.0294                                                       \n",
      "Epoch [7/17], Loss: 0.0318                                                       \n",
      "Epoch [8/17], Loss: 0.0300                                                       \n",
      "Epoch [9/17], Loss: 0.0317                                                       \n",
      "Epoch [10/17], Loss: 0.0308                                                      \n",
      "Checkpoint saved at backend/checkpoints/test_10.pth                              \n",
      "Epoch [11/17], Loss: 0.0321                                                      \n",
      "Epoch [12/17], Loss: 0.0316                                                      \n",
      "Epoch [13/17], Loss: 0.0327                                                      \n",
      "Epoch [14/17], Loss: 0.0322                                                      \n",
      "Epoch [15/17], Loss: 0.0331                                                      \n",
      "Checkpoint saved at backend/checkpoints/test_15.pth                              \n",
      "Epoch [16/17], Loss: 0.0327                                                      \n",
      "Epoch [17/17], Loss: 0.0334                                                      \n",
      "Test Loss: 0.0210                                                                \n",
      "100%|██████████| 5/5 [00:09<00:00,  1.95s/trial, best loss: 0.019916569806490807]\n",
      "{'epochs': 20.0, 'learning_rate': 0.029838439085646224}\n"
     ]
    }
   ],
   "source": [
    "# Define the search space for hyperparameters\n",
    "model_params_space = {\n",
    "    'input_size': data_processor.seq_length,\n",
    "    'output_size': data_processor.pred_window\n",
    "}\n",
    "\n",
    "# Run hyperparameter optimization\n",
    "best_hyperparams = ModelService.hyperparameter_optimization(LinRegNN, x_train, y_train, x_test, y_test, model_params_space, max_evals=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 20.0, 'learning_rate': 0.029838439085646224}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract best hyperparameters\n",
    "# best_hidden_size = best_hyperparams['model_params']['hidden_size']\n",
    "best_learning_rate = best_hyperparams['learning_rate']\n",
    "best_epochs = int(best_hyperparams['epochs'])\n",
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with best hyperparameters\n",
    "model = LinRegNN(data_processor.seq_length, data_processor.pred_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memilio-piotto\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Usuario\\.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\projects\\times_fw\\wandb\\run-20240603_104634-28uz6028</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emilio-piotto/times_fw/runs/28uz6028' target=\"_blank\">fiery-water-5</a></strong> to <a href='https://wandb.ai/emilio-piotto/times_fw' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emilio-piotto/times_fw' target=\"_blank\">https://wandb.ai/emilio-piotto/times_fw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emilio-piotto/times_fw/runs/28uz6028' target=\"_blank\">https://wandb.ai/emilio-piotto/times_fw/runs/28uz6028</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.2422\n",
      "Epoch [2/20], Loss: 0.0437\n",
      "Epoch [3/20], Loss: 0.1038\n",
      "Epoch [4/20], Loss: 0.0388\n",
      "Epoch [5/20], Loss: 0.1163\n",
      "Checkpoint saved at backend/checkpoints/lr01_5.pth\n",
      "Epoch [6/20], Loss: 0.0521\n",
      "Epoch [7/20], Loss: 0.1554\n",
      "Epoch [8/20], Loss: 0.0793\n",
      "Epoch [9/20], Loss: 0.2132\n",
      "Epoch [10/20], Loss: 0.1067\n",
      "Checkpoint saved at backend/checkpoints/lr01_10.pth\n",
      "Epoch [11/20], Loss: 0.2436\n",
      "Epoch [12/20], Loss: 0.1077\n",
      "Epoch [13/20], Loss: 0.2227\n",
      "Epoch [14/20], Loss: 0.0875\n",
      "Epoch [15/20], Loss: 0.1847\n",
      "Checkpoint saved at backend/checkpoints/lr01_15.pth\n",
      "Epoch [16/20], Loss: 0.0684\n",
      "Epoch [17/20], Loss: 0.1578\n",
      "Epoch [18/20], Loss: 0.0585\n",
      "Epoch [19/20], Loss: 0.1463\n",
      "Epoch [20/20], Loss: 0.0566\n",
      "Checkpoint saved at backend/checkpoints/lr01_20.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>average_loss</td><td>█▁▃▁▄▁▅▂▇▃█▃▇▃▆▂▅▂▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>average_loss</td><td>0.05656</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fiery-water-5</strong> at: <a href='https://wandb.ai/emilio-piotto/times_fw/runs/28uz6028' target=\"_blank\">https://wandb.ai/emilio-piotto/times_fw/runs/28uz6028</a><br/> View project at: <a href='https://wandb.ai/emilio-piotto/times_fw' target=\"_blank\">https://wandb.ai/emilio-piotto/times_fw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240603_104634-28uz6028\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01961362314831114"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_hyperparams['learning_rate'])\n",
    "\n",
    "# Training loop\n",
    "ms = ModelService.wandb_login()\n",
    "# ms.wandb_login()\n",
    "model.train_loop(model, criterion, optimizer, x_train, y_train, epochs=best_epochs, directory = \"backend/checkpoints/lr01_\", wandb_project=\"times_fw\")\n",
    "# Eval\n",
    "model.evaluation(model, x_test, y_test, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "model.register(model, name=\"template_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from backend.model_service import ModelService\n",
    "model_service = ModelService()\n",
    "loaded_model = model_service.load_registered_model(\"backend/models/template_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
