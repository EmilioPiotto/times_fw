{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from backend.data_processing_service import DataProcessingService\n",
    "\n",
    "# Initialize DataProcessingService\n",
    "data_processor = DataProcessingService(seq_length=10, pred_window=1, batch_size=10)\n",
    "data = np.loadtxt('data/normalized_apple_prices.csv')\n",
    "# data = data_processor.get_sample_data(length=50)\n",
    "\n",
    "# Normalize the data\n",
    "data_normalized, scaler = data_processor.normalize_data(data)\n",
    "\n",
    "# Create sequences\n",
    "x_data, y_data = data_processor.create_sequences(data_normalized)\n",
    "\n",
    "# Split data into training and test sets\n",
    "x_train, x_test, y_train, y_test = data_processor.split_data(x_data, y_data, train_ratio=0.8)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([102, 10, 1]) torch.Size([102, 1, 1]) torch.Size([26, 10, 1]) torch.Size([26, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.model_service import ModelService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TimeSeriesGenerator(ModelService):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super(TimeSeriesGenerator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            # nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def reshape_input(s):\n",
    "        return s.permute(0, 2, 1)\n",
    "\n",
    "class TimeSeriesDiscriminator(ModelService):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(TimeSeriesDiscriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def reshape_input(s):\n",
    "        return s.permute(0, 2, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(ModelService):\n",
    "    def __init__(self, generator, discriminator, gen_input_dim, data_dim, lr=0.0002, betas=(0.5, 0.999)):\n",
    "        super(GAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.gen_input_dim = gen_input_dim\n",
    "        self.data_dim = data_dim\n",
    "        \n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=betas)\n",
    "        self.optimizer_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "    def train(self, x_train, y_train, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(len(x_train)):\n",
    "                real_data = x_train[i]\n",
    "                real_labels = y_train[i].unsqueeze(1)\n",
    "\n",
    "                noise = real_data.t()\n",
    "                # Train Discriminator\n",
    "                self.optimizer_d.zero_grad()\n",
    "                \n",
    "                # Real data\n",
    "                real_output = self.discriminator(real_data.t())         # Extract reshaping too the Discrimiator class\n",
    "                real_loss = self.criterion(real_output, real_labels.squeeze(0))\n",
    "                \n",
    "                # Fake data\n",
    "                # noise = torch.randn(1, self.gen_input_dim)\n",
    "                fake_data = self.generator(noise)\n",
    "                fake_labels = torch.zeros(1, 1)  # Fake labels are 0\n",
    "                fake_output = self.discriminator(fake_data)\n",
    "                fake_loss = self.criterion(fake_output, fake_labels)\n",
    "                \n",
    "                # Total discriminator loss\n",
    "                d_loss = real_loss + fake_loss\n",
    "                d_loss.backward()\n",
    "                self.optimizer_d.step()\n",
    "                \n",
    "                # Train Generator\n",
    "                self.optimizer_g.zero_grad()\n",
    "                \n",
    "                # noise = torch.randn(1, self.gen_input_dim)\n",
    "                fake_data = self.generator(noise)\n",
    "                fake_output = self.discriminator(fake_data)\n",
    "                g_loss = self.criterion(fake_output, real_labels)\n",
    "                \n",
    "                g_loss.backward()\n",
    "                self.optimizer_g.step()\n",
    "            \n",
    "            print(f'Epoch [{epoch+1}/{epochs}]  Loss D: {d_loss.item()}, Loss G: {g_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\times_fw\\.venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1, 1, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]  Loss D: 0.4205183982849121, Loss G: 0.22290702164173126\n",
      "Epoch [2/10]  Loss D: 0.15232141315937042, Loss G: 0.03129754215478897\n",
      "Epoch [3/10]  Loss D: 0.0774698406457901, Loss G: 0.012773692607879639\n",
      "Epoch [4/10]  Loss D: 0.04704451188445091, Loss G: 0.009640452452003956\n",
      "Epoch [5/10]  Loss D: 0.031687673181295395, Loss G: 0.008547845296561718\n",
      "Epoch [6/10]  Loss D: 0.02274084836244583, Loss G: 0.008011503145098686\n",
      "Epoch [7/10]  Loss D: 0.017758162692189217, Loss G: 0.007759559899568558\n",
      "Epoch [8/10]  Loss D: 0.014956362545490265, Loss G: 0.0076571376994252205\n",
      "Epoch [9/10]  Loss D: 0.013363776728510857, Loss G: 0.007603437174111605\n",
      "Epoch [10/10]  Loss D: 0.012574374675750732, Loss G: 0.0075658755376935005\n"
     ]
    }
   ],
   "source": [
    "# Usage example:\n",
    "# Define model parameters\n",
    "gen_input_dim = 10\n",
    "# data_dim = 30  # Length of the time series\n",
    "input_size = data_processor.seq_length\n",
    "hidden_dim = 64\n",
    "# output_size = data_processor.pred_window\n",
    "\n",
    "# Instantiate models\n",
    "# generator = TimeSeriesGenerator(gen_input_dim, data_dim, hidden_dim)\n",
    "generator = TimeSeriesGenerator(input_dim=gen_input_dim, output_dim=input_size, hidden_dim=hidden_dim)\n",
    "# discriminator = TimeSeriesDiscriminator(data_dim, hidden_dim)\n",
    "discriminator = TimeSeriesDiscriminator(input_dim=input_size, hidden_dim=hidden_dim)\n",
    "gan = GAN(generator, discriminator, gen_input_dim, input_size)\n",
    "\n",
    "# Train the GAN model\n",
    "epochs = 10\n",
    "gan.train(x_train, y_train, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0986],\n",
       "         [ 0.0676],\n",
       "         [-0.0713],\n",
       "         [-0.0696],\n",
       "         [-0.0396],\n",
       "         [-0.0436],\n",
       "         [ 0.0216],\n",
       "         [ 0.0265],\n",
       "         [-0.0417],\n",
       "         [-0.0789]]),\n",
       " tensor([[-0.0580]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[-3], y_test[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0586]], grad_fn=<SigmoidBackward0>),\n",
       " tensor([[0.0586]], grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Pass test data through discriminator (optional)\n",
    "test_predictions = gan.discriminator(x_test[-3].t())\n",
    "\n",
    "# 3. Evaluate generated data using discriminator (optional)\n",
    "generated_predictions = gan.discriminator(x_test[-3].t())\n",
    "test_predictions, generated_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0713],\n",
       "         [-0.0696],\n",
       "         [-0.0396],\n",
       "         [-0.0436],\n",
       "         [ 0.0216],\n",
       "         [ 0.0265],\n",
       "         [-0.0417],\n",
       "         [-0.0789],\n",
       "         [-0.0580],\n",
       "         [ 0.2306]]),\n",
       " tensor([[0.3360]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 1\n",
    "x_test[-a], y_test[-a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0744]], grad_fn=<SigmoidBackward0>),\n",
       " tensor([[0.0744]], grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Pass test data through discriminator (optional)\n",
    "test_predictions = gan.discriminator(x_test[-a].t())\n",
    "\n",
    "# 3. Evaluate generated data using discriminator (optional)\n",
    "generated_predictions = gan.discriminator(x_test[-a].t())\n",
    "test_predictions, generated_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
