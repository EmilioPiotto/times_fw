{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from backend.data_processing_service import DataProcessingService\n",
    "\n",
    "# Initialize DataProcessingService\n",
    "data_processor = DataProcessingService(seq_length=10, pred_window=5, batch_size=10)\n",
    "data = np.loadtxt('data/normalized_apple_prices.csv')\n",
    "# data = data_processor.get_sample_data(length=50)\n",
    "\n",
    "# Normalize the data\n",
    "data_normalized, scaler = data_processor.normalize_data(data)\n",
    "\n",
    "# Create sequences\n",
    "x_data, y_data = data_processor.create_sequences(data_normalized)\n",
    "\n",
    "# Split data into training and test sets\n",
    "x_train, x_test, y_train, y_test = data_processor.split_data(x_data, y_data, train_ratio=0.8)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([99, 10, 1]) torch.Size([99, 5, 1]) torch.Size([25, 10, 1]) torch.Size([25, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.model_service import ModelService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TimeSeriesGenerator(ModelService):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super(TimeSeriesGenerator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            # nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "\n",
    "class TimeSeriesDiscriminator(ModelService):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(TimeSeriesDiscriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid() # 0 fake, 1 real\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\times_fw\\.venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([5, 1, 1])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]  Loss D: 0.5007985830307007, Loss G: 0.14317576587200165\n",
      "Epoch [2/10]  Loss D: 0.5003405213356018, Loss G: 0.1382562518119812\n",
      "Epoch [3/10]  Loss D: 0.5002017021179199, Loss G: 0.1364590972661972\n",
      "Epoch [4/10]  Loss D: 0.5001502633094788, Loss G: 0.13654480874538422\n",
      "Epoch [5/10]  Loss D: 0.5001226663589478, Loss G: 0.13730831444263458\n",
      "Epoch [6/10]  Loss D: 0.5001023411750793, Loss G: 0.13827991485595703\n",
      "Epoch [7/10]  Loss D: 0.5000864267349243, Loss G: 0.13883176445960999\n",
      "Epoch [8/10]  Loss D: 0.5000739693641663, Loss G: 0.1391364336013794\n",
      "Epoch [9/10]  Loss D: 0.5000638365745544, Loss G: 0.13898268342018127\n",
      "Epoch [10/10]  Loss D: 0.5000554323196411, Loss G: 0.13865412771701813\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class GAN(ModelService):\n",
    "    def __init__(self, generator, discriminator, gen_input_dim, data_dim, lr=0.0002, betas=(0.5, 0.999)):\n",
    "        super(GAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.gen_input_dim = gen_input_dim\n",
    "        self.data_dim = data_dim\n",
    "        \n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer_g = optim.Adam(self.generator.parameters(), lr=lr, betas=betas)\n",
    "        self.optimizer_d = optim.Adam(self.discriminator.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "    def train(self, x_train, y_train, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(len(x_train)):\n",
    "                real_data = x_train[i]\n",
    "                real_labels = y_train[i].unsqueeze(1)\n",
    "\n",
    "                ### Train Generator\n",
    "                self.optimizer_g.zero_grad()\n",
    "                \n",
    "                noise = real_data.t()\n",
    "                g_prediction = self.generator(noise)\n",
    "\n",
    "                # Loss for Generator (compared to real labels)\n",
    "                g_real_loss = self.criterion(g_prediction, real_labels)\n",
    "\n",
    "                # Combine real data and generated data for the Discriminator\n",
    "                g_prediction_combined = torch.cat((real_data, g_prediction.t()))[:self.gen_input_dim].t()\n",
    "\n",
    "                ### Train Discriminator\n",
    "                self.optimizer_d.zero_grad()\n",
    "\n",
    "                # Real data loss for Discriminator\n",
    "                real_output = self.discriminator(real_data.t())\n",
    "                real_loss = self.criterion(real_output, torch.ones_like(real_output))\n",
    "                \n",
    "                # Fake data loss for Discriminator\n",
    "                fake_output = self.discriminator(g_prediction_combined.detach())  # detach to avoid backprop through G\n",
    "                fake_loss = self.criterion(fake_output, torch.zeros_like(fake_output))\n",
    "                \n",
    "                # Total Discriminator loss\n",
    "                d_loss = real_loss + fake_loss\n",
    "                d_loss.backward()\n",
    "                self.optimizer_d.step()\n",
    "\n",
    "                # Optimize Generator again against Discriminator's output\n",
    "                fake_output_for_g = self.discriminator(g_prediction_combined)\n",
    "                g_loss_against_discriminator = self.criterion(fake_output_for_g, torch.ones_like(fake_output_for_g))\n",
    "                \n",
    "                # Total Generator loss\n",
    "                g_loss = g_real_loss * 0.5 + g_loss_against_discriminator * 0.5\n",
    "                g_loss.backward(retain_graph=True)\n",
    "                self.optimizer_g.step()\n",
    "\n",
    "            print(f'Epoch [{epoch+1}/{epochs}]  Loss D: {d_loss.item()}, Loss G: {g_loss.item()}')\n",
    "\n",
    "# Define model parameters\n",
    "# data_processor = DataProcessingService(seq_length=10, pred_window=1, batch_size=10) (1st cell)\n",
    "gen_input_dim = data_processor.seq_length\n",
    "gen_output_dim = data_processor.pred_window\n",
    "gen_hidden_dim = 32\n",
    "dis_input_dim = 10\n",
    "dis_hidden_dim = 16\n",
    "\n",
    "# Instantiate models\n",
    "generator = TimeSeriesGenerator(input_dim=gen_input_dim, output_dim=gen_output_dim, hidden_dim=gen_hidden_dim)\n",
    "discriminator = TimeSeriesDiscriminator(input_dim=dis_input_dim, hidden_dim=dis_hidden_dim)\n",
    "gan = GAN(generator, discriminator, gen_input_dim, gen_output_dim)\n",
    "\n",
    "# Train the GAN model\n",
    "epochs = 10\n",
    "gan.train(x_train, y_train, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\times_fw\\.venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([5, 1])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02972451189532876"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = generator\n",
    "criterion = nn.MSELoss()\n",
    "x_test_rs = x_test.permute(0, 2, 1)\n",
    "model.evaluation(model, x_test_rs, y_test, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0302],\n",
       "         [ 0.0372],\n",
       "         [ 0.0924],\n",
       "         [-0.1962],\n",
       "         [-0.0986],\n",
       "         [ 0.0676],\n",
       "         [-0.0713],\n",
       "         [-0.0696],\n",
       "         [-0.0396],\n",
       "         [-0.0436]]),\n",
       " tensor([[ 0.0216],\n",
       "         [ 0.0265],\n",
       "         [-0.0417],\n",
       "         [-0.0789],\n",
       "         [-0.0580]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 3\n",
    "x_test[-a], y_test[-a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1145, -0.1221, -0.0591, -0.1408, -0.0359]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Evaluate generated data using discriminator (optional)\n",
    "gan.generator(x_test[-a].t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
