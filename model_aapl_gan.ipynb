{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from backend.data_processing_service import DataProcessingService\n",
    "\n",
    "# Initialize DataProcessingService\n",
    "data_processor = DataProcessingService(seq_length=10, pred_window=1, batch_size=10)\n",
    "data = np.loadtxt('data/normalized_apple_prices.csv')\n",
    "# data = data_processor.get_sample_data(length=50)\n",
    "\n",
    "# Normalize the data\n",
    "data_normalized, scaler = data_processor.normalize_data(data)\n",
    "\n",
    "# Create sequences\n",
    "x_data, y_data = data_processor.create_sequences(data_normalized)\n",
    "\n",
    "# Split data into training and test sets\n",
    "x_train, x_test, y_train, y_test = data_processor.split_data(x_data, y_data, train_ratio=0.8)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([102, 10, 1]) torch.Size([102, 1, 1]) torch.Size([26, 10, 1]) torch.Size([26, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.model_service import ModelService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TimeSeriesGenerator(ModelService):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super(TimeSeriesGenerator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            # nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def reshape_input(s):\n",
    "        return s.permute(0, 2, 1)\n",
    "\n",
    "class TimeSeriesDiscriminator(ModelService):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(TimeSeriesDiscriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def reshape_input(s):\n",
    "        return s.permute(0, 2, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(ModelService):\n",
    "    def __init__(self, generator, discriminator, gen_input_dim, data_dim, lr=0.0002, betas=(0.5, 0.999)):\n",
    "        super(GAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.gen_input_dim = gen_input_dim\n",
    "        self.data_dim = data_dim\n",
    "        \n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=betas)\n",
    "        self.optimizer_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "    def train(self, x_train, y_train, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(len(x_train)):\n",
    "                real_data = x_train[i]\n",
    "                real_labels = y_train[i].unsqueeze(1)\n",
    "\n",
    "                # Train Discriminator\n",
    "                self.optimizer_d.zero_grad()\n",
    "                \n",
    "                # Real data\n",
    "                real_output = self.discriminator(real_data.t())         # Extract reshaping too the Discrimiator class\n",
    "                real_loss = self.criterion(real_output, real_labels.squeeze(0))\n",
    "                \n",
    "                # Fake data\n",
    "                noise = torch.randn(1, self.gen_input_dim)\n",
    "                fake_data = self.generator(noise)\n",
    "                fake_labels = torch.zeros(1, 1)  # Fake labels are 0\n",
    "                fake_output = self.discriminator(fake_data)\n",
    "                fake_loss = self.criterion(fake_output, fake_labels)\n",
    "                \n",
    "                # Total discriminator loss\n",
    "                d_loss = real_loss + fake_loss\n",
    "                d_loss.backward()\n",
    "                self.optimizer_d.step()\n",
    "                \n",
    "                # Train Generator\n",
    "                self.optimizer_g.zero_grad()\n",
    "                \n",
    "                noise = torch.randn(1, self.gen_input_dim)\n",
    "                fake_data = self.generator(noise)\n",
    "                fake_output = self.discriminator(fake_data)\n",
    "                g_loss = self.criterion(fake_output, real_labels)\n",
    "                \n",
    "                g_loss.backward()\n",
    "                self.optimizer_g.step()\n",
    "            \n",
    "            print(f'Epoch [{epoch+1}/{epochs}]  Loss D: {d_loss.item()}, Loss G: {g_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\times_fw\\.venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1, 1, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]  Loss D: 0.5972247123718262, Loss G: 0.1938854455947876\n",
      "Epoch [2/10]  Loss D: 0.388442724943161, Loss G: 0.06010378897190094\n",
      "Epoch [3/10]  Loss D: 0.31770098209381104, Loss G: 0.01388280838727951\n",
      "Epoch [4/10]  Loss D: 0.2915491759777069, Loss G: 0.008138542994856834\n",
      "Epoch [5/10]  Loss D: 0.2804330587387085, Loss G: 0.008363691158592701\n",
      "Epoch [6/10]  Loss D: 0.27364087104797363, Loss G: 0.007428688928484917\n",
      "Epoch [7/10]  Loss D: 0.2699657678604126, Loss G: 0.0072815450839698315\n",
      "Epoch [8/10]  Loss D: 0.26761341094970703, Loss G: 0.0073517244309186935\n",
      "Epoch [9/10]  Loss D: 0.2665179371833801, Loss G: 0.007844784297049046\n",
      "Epoch [10/10]  Loss D: 0.2646543085575104, Loss G: 0.007210987154394388\n"
     ]
    }
   ],
   "source": [
    "# Usage example:\n",
    "# Define model parameters\n",
    "gen_input_dim = 10\n",
    "# data_dim = 30  # Length of the time series\n",
    "input_size = data_processor.seq_length\n",
    "hidden_dim = 64\n",
    "# output_size = data_processor.pred_window\n",
    "\n",
    "# Instantiate models\n",
    "# generator = TimeSeriesGenerator(gen_input_dim, data_dim, hidden_dim)\n",
    "generator = TimeSeriesGenerator(input_dim=gen_input_dim, output_dim=input_size, hidden_dim=hidden_dim)\n",
    "# discriminator = TimeSeriesDiscriminator(data_dim, hidden_dim)\n",
    "discriminator = TimeSeriesDiscriminator(input_dim=input_size, hidden_dim=hidden_dim)\n",
    "gan = GAN(generator, discriminator, gen_input_dim, input_size)\n",
    "\n",
    "# Train the GAN model\n",
    "epochs = 10\n",
    "gan.train(x_train, y_train, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0986],\n",
       "         [ 0.0676],\n",
       "         [-0.0713],\n",
       "         [-0.0696],\n",
       "         [-0.0396],\n",
       "         [-0.0436],\n",
       "         [ 0.0216],\n",
       "         [ 0.0265],\n",
       "         [-0.0417],\n",
       "         [-0.0789]]),\n",
       " tensor([[-0.0580]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[-3], y_test[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Pass test data through discriminator (optional)\n",
    "test_predictions = gan.discriminator(x_test[-3].t())\n",
    "\n",
    "# 3. Evaluate generated data using discriminator (optional)\n",
    "generated_predictions = gan.discriminator(x_test[-3].t())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0991]], grad_fn=<SigmoidBackward0>),\n",
       " tensor([[0.0991]], grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions, generated_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.1760\n",
      "Epoch [2/10], Loss: 0.1008\n",
      "Epoch [3/10], Loss: 0.0839\n",
      "Epoch [4/10], Loss: 0.0741\n",
      "Epoch [5/10], Loss: 0.0655\n",
      "Checkpoint saved at epoch 5\n",
      "Epoch [6/10], Loss: 0.0581\n",
      "Epoch [7/10], Loss: 0.0518\n",
      "Epoch [8/10], Loss: 0.0467\n",
      "Epoch [9/10], Loss: 0.0425\n",
      "Epoch [10/10], Loss: 0.0392\n",
      "Checkpoint saved at epoch 10\n",
      "Test Loss: 0.0181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.018084477803628173"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "input_size = data_processor.seq_length\n",
    "output_size = data_processor.pred_window\n",
    "model = LinRegNN(input_size, output_size)\n",
    "\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "x_train_rs,x_test_rs= model.reshape_input(x_train),model.reshape_input(x_test)\n",
    "epochs = 10\n",
    "model.train_loop(model, criterion, optimizer, x_train_rs, y_train, epochs, directory = \"backend/checkpoints/lr01_\")\n",
    "# Eval\n",
    "model.evaluation(model, x_test_rs, y_test, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "model.register(model, name=\"template_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from backend.model_service import ModelService\n",
    "model_service = ModelService()\n",
    "loaded_model = model_service.load_registered_model(\"backend/models/template_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
